### API Providers vs Self Deployment

Inference API Providers - Open AI / Gemini / Claude etc.

Self-Deployments in the Cloud - Llama, Custom fine tuned models

----

| Criteria | Inference API Providers | Self-Deployments in the Cloud |
|----------|------------------------|------------------------------|
| Model customization possible | âŒ Harder | âœ… Easier |
| Setup/maintenance overhead | âœ… Easier | âŒ Harder |
| Throughput at large scale | ğŸ”½ Lower | ğŸ”¼ Higher |
| Cost per output at small scale | ğŸ’² Cheaper | ğŸ’² More Expensive |
| Cost per output at large scale | ğŸ’² More Expensive | ğŸ’² Cheaper |
| Control over data privacy/security | ğŸ”’ Less Control | ğŸ”’ More Control |

---
Ref: https://x.com/modal_labs/status/1892608033026441266

---


Throughput - How many requests a server can handle simultaneously without slowing down.

