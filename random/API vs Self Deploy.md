### API Providers vs Self Deployment

Inference API Providers - Open AI / Gemini / Claude etc.

Self-Deployments in the Cloud - Llama, Custom fine tuned models

----

| Criteria | Inference API Providers | Self-Deployments in the Cloud |
|----------|------------------------|------------------------------|
| Model customization possible | ❌ Harder | ✅ Easier |
| Setup/maintenance overhead | ✅ Easier | ❌ Harder |
| Throughput at large scale | 🔽 Lower | 🔼 Higher |
| Cost per output at small scale | 💲 Cheaper | 💲 More Expensive |
| Cost per output at large scale | 💲 More Expensive | 💲 Cheaper |
| Control over data privacy/security | 🔒 Less Control | 🔒 More Control |

---
Ref: https://x.com/modal_labs/status/1892608033026441266

---


Throughput - How many requests a server can handle simultaneously without slowing down.

